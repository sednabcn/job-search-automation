name: Job Manager Center MultiPlaform
# Fully integrated with professional-job-center-cli.py

on:
  schedule:
    - cron: '0 6 * * *'  # Daily at 6 AM UTC
  
  workflow_dispatch:
    inputs:
      job_positions:
        description: 'Job positions (comma-separated)'
        required: true
        default: 'Senior Software Engineer,Staff Engineer,Tech Lead,Engineering Manager'
        type: string
      
      update_config:
        description: 'Auto-update job-manager-config.yml'
        required: true
        default: true
        type: boolean
      
      trigger_discovery:
        description: 'Trigger job discovery after config update'
        required: true
        default: true
        type: boolean
      
      skip_boards:
        description: 'Skip specific boards (comma-separated)'
        required: false
        default: ''
        type: string
      
      mode:
        description: 'Execution mode'
        required: false
        default: 'full'
        type: choice
        options:
          - full
          - extract-only
          - discover-only

env:
  PYTHON_VERSION: '3.10'
  TIMEZONE: 'Europe/London'
  CLI_TOOL: '.github/scripts/professional_job_center_cli.py'
  EXTRACT_COMMAND: 'extract-keywords'

jobs:
  # ========================================
  # STAGE 1: VALIDATE & PREPARE
  # ========================================
  prepare:
    name: 🔧 Prepare Environment
    runs-on: ubuntu-latest
    outputs:
      job_positions: ${{ steps.parse.outputs.job_positions }}
      job_positions_args: ${{ steps.parse.outputs.job_positions_args }}
      boards_to_process: ${{ steps.parse.outputs.boards }}
      run_id: ${{ steps.setup.outputs.run_id }}
      timestamp: ${{ steps.setup.outputs.timestamp }}
      mode: ${{ steps.setup.outputs.mode }}
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install Dependencies
        run: |
          pip install --upgrade pip
          pip install pyyaml requests beautifulsoup4 selenium

      - name: Parse and Validate Inputs
        id: parse
        run: |
          # Get job positions from input
          POSITIONS="${{ github.event.inputs.job_positions }}"
          if [ -z "$POSITIONS" ]; then
            POSITIONS="Senior Software Engineer,Staff Engineer,Tech Lead,Engineering Manager"
          fi

          # Convert comma-separated positions into JSON array for output
          POSITIONS_JSON=$(python3 -c "
          import json
          positions = '''$POSITIONS'''.split(',')
          positions = [p.strip() for p in positions if p.strip()]
          print(json.dumps(positions))
          ")
          
          # Convert positions to space-separated WITHOUT extra quotes
          # This is what the CLI expects
          IFS=',' read -r -a pos_array <<< "$POSITIONS"
          POSITIONS_ARGS=""
          for p in "${pos_array[@]}"; do
            p_trimmed=$(echo "$p" | xargs)
            # Add quotes around multi-word positions
            if [[ "$p_trimmed" == *" "* ]]; then
              POSITIONS_ARGS+="\"$p_trimmed\" "
            else
              POSITIONS_ARGS+="$p_trimmed "
            fi
          done
          
          # Remove trailing space
          POSITIONS_ARGS=$(echo "$POSITIONS_ARGS" | sed 's/ $//')

          # Save outputs for later steps
          echo "job_positions=$POSITIONS_JSON" >> $GITHUB_OUTPUT
          echo "job_positions_args=$POSITIONS_ARGS" >> $GITHUB_OUTPUT

          # Debug output
          echo "ℹ️ Positions JSON: $POSITIONS_JSON"
          echo "ℹ️ Positions Args: $POSITIONS_ARGS"

          # Determine boards to process
          SKIP_BOARDS="${{ github.event.inputs.skip_boards }}"
          BOARDS="linkedin,glassdoor,reed,indeed"

          if [ -n "$SKIP_BOARDS" ]; then
            BOARDS=$(python3 -c "
          skip = '''$SKIP_BOARDS'''.split(',')
          skip = [b.strip().lower() for b in skip if b.strip()]
          all_boards = ['linkedin', 'glassdoor', 'reed', 'indeed']
          boards = [b for b in all_boards if b not in skip]
          print(','.join(boards))
          ")
          fi

          echo "boards=$BOARDS" >> $GITHUB_OUTPUT
          echo "ℹ️ Boards: $BOARDS"
          
      - name: Initialize Run Context
        id: setup
        run: |
          RUN_ID="job-search-$(date +%Y%m%d-%H%M%S)"
          TIMESTAMP=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
          MODE="${{ github.event.inputs.mode }}"
          MODE="${MODE:-full}"
          
          echo "run_id=$RUN_ID" >> $GITHUB_OUTPUT
          echo "timestamp=$TIMESTAMP" >> $GITHUB_OUTPUT
          echo "mode=$MODE" >> $GITHUB_OUTPUT
          
          echo "🚀 Starting Job Search Automation"
          echo "Run ID: $RUN_ID"
          echo "Mode: $MODE"
      
      - name: Validate CLI Tool
        run: |
          if [ ! -f "${{ env.CLI_TOOL }}" ]; then
            echo "❌ CLI tool not found: ${{ env.CLI_TOOL }}"
            exit 1
          fi
          
          chmod +x "${{ env.CLI_TOOL }}"
          python3 "${{ env.CLI_TOOL }}" --help
          echo "✅ CLI tool validated"

  # ========================================
  # STAGE 2: DISCOVER JOBS FROM ALL BOARDS
  # ========================================
  discover-jobs:
    name: 🔍 Discover Jobs - ${{ matrix.board }}
    runs-on: ubuntu-latest
    needs: prepare
    if: |
      needs.prepare.outputs.mode == 'full' || 
      needs.prepare.outputs.mode == 'discover-only'
    strategy:
      matrix:
        board: [linkedin, glassdoor, reed, indeed]
      fail-fast: false
      max-parallel: 2
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
      
      - name: Check if Board Enabled
        id: check_board
        run: |
          BOARDS="${{ needs.prepare.outputs.boards_to_process }}"
          if [[ "$BOARDS" == *"${{ matrix.board }}"* ]]; then
            echo "enabled=true" >> $GITHUB_OUTPUT
            echo "✅ ${{ matrix.board }} enabled"
          else
            echo "enabled=false" >> $GITHUB_OUTPUT
            echo "⏭️ Skipping ${{ matrix.board }}"
          fi
      
      - name: Setup Python
        if: steps.check_board.outputs.enabled == 'true'
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install Dependencies
        if: steps.check_board.outputs.enabled == 'true'
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
          
          # Install board-specific dependencies
          case "${{ matrix.board }}" in
            linkedin|glassdoor|indeed)
              pip install selenium webdriver-manager
              ;;
            reed)
              pip install requests
              ;;
          esac
      
      - name: Setup Chrome (for Selenium)
        if: |
          steps.check_board.outputs.enabled == 'true' && 
          matrix.board != 'reed'
        uses: browser-actions/setup-chrome@latest

      - name: Initialize Board Activity Files
        if: steps.check_board.outputs.enabled == 'true'
        run: |
          # Create default activity file if it doesn't exist or is invalid
          ACTIVITY_FILE="${{ matrix.board }}_activity.json"
          
          if [ ! -f "$ACTIVITY_FILE" ] || ! python3 -c "import json; json.load(open('$ACTIVITY_FILE'))" 2>/dev/null; then
            echo "🔧 Creating default activity file for ${{ matrix.board }}"
            cat > "$ACTIVITY_FILE" << 'EOF'
          {
            "last_reset": "2000-01-01",
            "daily_actions": 0,
            "search_count": 0,
            "apply_count": 0,
            "profile_views": 0,
            "connections": 0
          }
          EOF
            echo "✅ Activity file initialized"
          fi

      - name: Discover Jobs - ${{ matrix.board }}
        if: steps.check_board.outputs.enabled == 'true'
        run: |
          echo "🔍 Discovering jobs on ${{ matrix.board }}..."
          
          OUTPUT_FILE="${{ matrix.board }}_jobs.json"
          
          case "${{ matrix.board }}" in
            linkedin)
              # Check if LinkedIn automation script exists
              if [ -f ".github/scripts/linkedin_automation.py" ]; then
                echo "Running LinkedIn automation..."
                python3 .github/scripts/linkedin_automation.py \
                  --mode discover \
                  --output "$OUTPUT_FILE" \
                  --headless \
                  --max-results 50 || {
                    echo "⚠️ LinkedIn automation failed, creating empty file"
                    echo '[]' > "$OUTPUT_FILE"
                  }
              else
                echo "⚠️ LinkedIn automation script not found"
                echo "💡 Creating placeholder file"
                echo '[]' > "$OUTPUT_FILE"
              fi
              ;;
            
            glassdoor)
              python3 .github/scripts/glassdoor_enhanced.py \
                --scrape \
                --output "$OUTPUT_FILE" \
                --max-pages 5
              ;;
            
            reed)
              if [ -n "${{ secrets.REED_API_KEY }}" ]; then
                python3 .github/scripts/reed_scraper.py \
                  --api \
                  --api-key "${{ secrets.REED_API_KEY }}" \
                  --output "$OUTPUT_FILE"
              else
                python3 .github/scripts/reed_scraper.py \
                  --scrape \
                  --output "$OUTPUT_FILE"
              fi
              ;;
            
            indeed)
              python3 .github/scripts/indeed_scraper.py \
                --search \
                --output "$OUTPUT_FILE" \
                --headless \
                --max-results 50
              ;;
          esac
          
          # Validate output
          if [ -f "$OUTPUT_FILE" ]; then
            JOB_COUNT=$(python3 -c "import json; data=json.load(open('$OUTPUT_FILE')); print(len(data) if isinstance(data, list) else len(data.get('jobs', [])))" 2>/dev/null || echo "0")
            echo "✅ Discovered $JOB_COUNT jobs from ${{ matrix.board }}"
          else
            echo "⚠️ No jobs file created, using empty list"
            echo "[]" > "$OUTPUT_FILE"
          fi
        env:
          LINKEDIN_EMAIL: ${{ secrets.LINKEDIN_EMAIL }}
          LINKEDIN_PASSWORD: ${{ secrets.LINKEDIN_PASSWORD }}
          GLASSDOOR_EMAIL: ${{ secrets.GLASSDOOR_EMAIL }}
          GLASSDOOR_PASSWORD: ${{ secrets.GLASSDOOR_PASSWORD }}
          REED_API_KEY: ${{ secrets.REED_API_KEY }}
        timeout-minutes: 15
        continue-on-error: true
      
      - name: Upload Discovered Jobs
        if: steps.check_board.outputs.enabled == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: discovered-jobs-${{ matrix.board }}
          path: ${{ matrix.board }}_jobs.json
          retention-days: 7
          
  # ========================================
  # STAGE 3: EXTRACT KEYWORDS & GENERATE CONFIG
  # ========================================
  extract-keywords:
    name: 🔑 Extract Keywords & Generate Config
    runs-on: ubuntu-latest
    needs: [prepare, discover-jobs]
    if: |
      always() && 
      (needs.prepare.outputs.mode == 'full' || 
       needs.prepare.outputs.mode == 'extract-only') &&
      (needs.discover-jobs.result == 'success' || 
       needs.discover-jobs.result == 'skipped')
    
    outputs:
      total_matches: ${{ steps.extraction.outputs.total_matches }}
      top_keywords: ${{ steps.extraction.outputs.top_keywords }}
      config_generated: ${{ steps.extraction.outputs.config_generated }}
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install Dependencies
        run: |
          pip install --upgrade pip
          pip install pyyaml requests beautifulsoup4
      
      - name: Download All Job Files
        uses: actions/download-artifact@v4
        with:
          pattern: discovered-jobs-*
          merge-multiple: true
        continue-on-error: true
      
      - name: List Downloaded Files
        run: |
          echo "📂 Downloaded job files:"
          ls -lh *_jobs.json 2>/dev/null || echo "No job files found"
      
      - name: Extract Keywords with CLI
        id: extraction
        run: |
          echo "🔑 Starting keyword extraction..."
          
          # Check if any job files exist
          if ! ls *_jobs.json 1> /dev/null 2>&1; then
            echo "⚠️ No job files found, creating empty files"
            for board in linkedin glassdoor reed indeed; do
              echo '[]' > "${board}_jobs.json"
            done
          fi
          
          # Get positions as space-separated string
          POSITIONS_INPUT="${{ needs.prepare.outputs.job_positions_args }}"
          echo "Positions input: $POSITIONS_INPUT"
          
          # Build CLI command with proper file paths
          python3 ${{ env.CLI_TOOL }} extract-keywords \
            --positions $POSITIONS_INPUT \
            --files *_jobs.json \
            --output keyword_analysis_report.json \
            --update-config || {
              echo "❌ Extraction failed, creating minimal config"
              cat > job-manager-config.yml << 'EOF'
          platforms:
            linkedin:
              max_results_per_search: 50
            glassdoor:
              max_results_per_search: 50
            reed:
              max_results_per_search: 50
            indeed:
              max_results_per_search: 50
          
          search:
            target_roles:
              - "Senior Software Engineer"
              - "Staff Engineer"
            default_location: "London"
          
          generated_at: "$(date -u +"%Y-%m-%dT%H:%M:%SZ")"
          
          metadata:
            total_jobs_analyzed: 0
            matching_jobs: 0
          
          matching:
            required_keywords: []
            preferred_keywords: []
            excluded_keywords: []
          EOF
            }
          
          # Set workflow outputs
          if [ -f keyword_analysis_report.json ]; then
            TOTAL_MATCHES=$(python3 -c "import json; d=json.load(open('keyword_analysis_report.json')); print(d.get('matching_jobs', 0))" 2>/dev/null || echo "0")
            echo "total_matches=$TOTAL_MATCHES" >> $GITHUB_OUTPUT
            
            TOP_KEYWORDS=$(python3 -c "import json; d=json.load(open('keyword_analysis_report.json')); k=[v.get('top_keywords', [])[:3] for v in d.get('keyword_analysis', {}).values()]; import itertools; print(','.join(list(itertools.chain(*k))[:8]))" 2>/dev/null || echo "")
            echo "top_keywords=$TOP_KEYWORDS" >> $GITHUB_OUTPUT
            echo "config_generated=true" >> $GITHUB_OUTPUT
          else
            echo "total_matches=0" >> $GITHUB_OUTPUT
            echo "top_keywords=" >> $GITHUB_OUTPUT
            echo "config_generated=true" >> $GITHUB_OUTPUT
          fi
        env:
          GITHUB_OUTPUT: ${{ github.output }}
      
      - name: Validate Generated Config
        run: |
          if [ ! -f job-manager-config.yml ]; then
            echo "❌ Config file not generated"
            exit 1
          fi
          
          echo "✅ Validating config file..."
          python3 << 'EOF'
          import yaml
          import sys
          
          try:
              with open('job-manager-config.yml', 'r') as f:
                  config = yaml.safe_load(f)
              
              # Validate structure - only check REQUIRED sections
              required = ['search', 'platforms']
              missing = [s for s in required if s not in config]
              
              if missing:
                  print(f"❌ Missing required sections: {missing}")
                  sys.exit(1)
              
              # Optional sections - just warn if missing
              optional = ['matching', 'generated_at', 'metadata']
              missing_optional = [s for s in optional if s not in config]
              if missing_optional:
                  print(f"⚠️ Missing optional sections: {missing_optional}")
              
              # Validate search section
              search = config.get('search', {})
              if not search.get('target_roles'):
                  print("⚠️ Warning: No target roles found")
              
              print("✅ Config validation passed")
              print(f"   Target roles: {len(search.get('target_roles', []))}")
              print(f"   Required keywords: {len(config.get('matching', {}).get('required_keywords', []))}")
              print(f"   Preferred keywords: {len(config.get('matching', {}).get('preferred_keywords', []))}")
              print(f"   Locations: {len(search.get('locations', []))}")
              
          except Exception as e:
              print(f"❌ Validation failed: {e}")
              sys.exit(1)
          EOF
      
      - name: Display Summary
        run: |
          if [ -f keyword_analysis_report.json ]; then
            python3 << 'EOF'
          import json
          from pathlib import Path
          
          with open('keyword_analysis_report.json', 'r') as f:
              report = json.load(f)
          
          print("\n" + "="*80)
          print("KEYWORD EXTRACTION SUMMARY")
          print("="*80)
          
          print(f"\n📊 OVERVIEW:")
          print(f"  Positions: {', '.join(report.get('positions_analyzed', []))}")
          print(f"  Total Jobs: {report.get('total_jobs', 0)}")
          print(f"  Matching: {report.get('matching_jobs', 0)}")
          
          print(f"\n📈 BY BOARD:")
          for board, stats in report.get('board_stats', {}).items():
              print(f"  {board.upper()}:")
              print(f"    Total: {stats.get('total_jobs', 0)}, Matching: {stats.get('matching_jobs', 0)}")
          
          print(f"\n🔑 TOP KEYWORDS:")
          for category, data in report.get('keyword_analysis', {}).items():
              keywords = ', '.join(data.get('top_keywords', [])[:5])
              if keywords:
                  print(f"  {category.upper()}: {keywords}")
          
          print(f"\n🏙️ TOP LOCATIONS:")
          print(f"  {', '.join(report.get('top_locations', [])[:5])}")
          
          print("\n" + "="*80)
          EOF
          fi
      
      - name: Backup Previous Config
        run: |
          if [ -f job-manager-config.yml ] && [ -d .git ]; then
            TIMESTAMP=$(date +%Y%m%d-%H%M%S)
            mkdir -p config_backups
            cp job-manager-config.yml "config_backups/job-manager-config-$TIMESTAMP.yml"
            echo "ℹ️ Previous config backed up"
          fi
      
      - name: Upload Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: keyword-extraction-results
          path: |
            job-manager-config.yml
            keyword_analysis_report.json
          retention-days: 30
      
      - name: Commit Updated Config
        if: |
          github.event.inputs.update_config == 'true' || 
          github.event_name == 'schedule'
        run: |
          git config user.name "🤖 Job Search Bot"
          git config user.email "bot@jobsearch.local"
          
          # Pull latest changes first to avoid conflicts
          git pull origin ${{ github.ref_name }} --rebase || true
          
          git add job-manager-config.yml
          git add keyword_analysis_report.json 2>/dev/null || true
          
          if git diff-index --quiet HEAD --; then
            echo "ℹ️ No changes to commit"
          else
            git commit -m "🤖 Auto-update: keyword extraction
          
          - Run ID: ${{ needs.prepare.outputs.run_id }}
          - Timestamp: ${{ needs.prepare.outputs.timestamp }}
          - Matching Jobs: ${{ steps.extraction.outputs.total_matches }}
          - Positions: ${{ needs.prepare.outputs.job_positions }}"
            
            # Push with retry logic
            for i in {1..3}; do
              if git push origin HEAD:${{ github.ref_name }}; then
                echo "✅ Config committed and pushed"
                break
              else
                echo "⚠️ Push failed, attempt $i/3"
                sleep 2
                git pull origin ${{ github.ref_name }} --rebase || true
              fi
            done
          fi
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  # ========================================
  # STAGE 4: TRIGGER DISCOVERY WORKFLOW
  # ========================================
  trigger-discovery:
    name: 🚀 Trigger Multi-Platform Discovery
    runs-on: ubuntu-latest
    needs: [prepare, extract-keywords]
    if: |
      (github.event.inputs.trigger_discovery == 'true' || 
       github.event_name == 'schedule') &&
      needs.extract-keywords.result == 'success' &&
      needs.extract-keywords.outputs.config_generated == 'true'
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
      
      - name: Trigger Discovery Workflow
        run: |
          echo "🚀 Triggering multi-platform job discovery..."
          
          # Check if workflow file exists
          if ! gh workflow list | grep -q "job-manager-center-multiplatform"; then
            echo "⚠️ Discovery workflow not found, skipping trigger"
            exit 0
          fi
          
          gh workflow run job-manager-center-multiplatform.yml \
            -f mode=full \
            -f job_boards=all \
            -f match_threshold=75 \
            -f auto_apply=false || {
              echo "⚠️ Failed to trigger workflow, but continuing"
            }
          
          echo "✅ Discovery workflow triggered"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        continue-on-error: true
      
      - name: Log Trigger
        run: |
          echo "Discovery workflow triggered at $(date -u +"%Y-%m-%dT%H:%M:%SZ")" >> .github/workflow_logs/trigger_log.txt
          git add .github/workflow_logs/trigger_log.txt
          git commit -m "Log: Discovery workflow triggered" || true
        continue-on-error: true

  # ========================================
  # STAGE 5: FINALIZE & NOTIFY
  # ========================================
  finalize:
    name: 📊 Finalize & Notify
    runs-on: ubuntu-latest
    needs: [prepare, extract-keywords, trigger-discovery]
    if: always()
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
      
      - name: Download Artifacts
        uses: actions/download-artifact@v4
        with:
          name: keyword-extraction-results
        continue-on-error: true
      
      - name: Generate Final Summary
        run: |
          echo "# 🎯 Job Search Automation Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## 📋 Run Details" >> $GITHUB_STEP_SUMMARY
          echo "- **Run ID**: ${{ needs.prepare.outputs.run_id }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Timestamp**: ${{ needs.prepare.outputs.timestamp }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Mode**: ${{ needs.prepare.outputs.mode }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Positions**: ${{ needs.prepare.outputs.job_positions }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## ✅ Stage Results" >> $GITHUB_STEP_SUMMARY
          echo "| Stage | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Preparation | ${{ needs.prepare.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Keyword Extraction | ${{ needs.extract-keywords.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Discovery Trigger | ${{ needs.trigger-discovery.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## 📊 Metrics" >> $GITHUB_STEP_SUMMARY
          echo "- **Total Matches**: ${{ needs.extract-keywords.outputs.total_matches }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Top Keywords**: ${{ needs.extract-keywords.outputs.top_keywords }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f keyword_analysis_report.json ]; then
            echo "## 📈 Detailed Analysis" >> $GITHUB_STEP_SUMMARY
            echo "See [keyword_analysis_report.json](keyword_analysis_report.json) for full details" >> $GITHUB_STEP_SUMMARY
          fi
      
      - name: Send Slack Notification
        if: success() && vars.SLACK_WEBHOOK_URL != ''
        run: |
          curl -X POST "${{ vars.SLACK_WEBHOOK_URL }}" \
            -H 'Content-Type: application/json' \
            -d '{
              "text": "🤖 Job Search Automation Complete",
              "blocks": [
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": "*Job Search Automation*\n✅ Successfully completed"
                  }
                },
                {
                  "type": "section",
                  "fields": [
                    {
                      "type": "mrkdwn",
                      "text": "*Run ID:*\n${{ needs.prepare.outputs.run_id }}"
                    },
                    {
                      "type": "mrkdwn",
                      "text": "*Matches:*\n${{ needs.extract-keywords.outputs.total_matches }}"
                    }
                  ]
                }
              ]
            }'
        continue-on-error: true
      
      - name: Create Issue on Failure
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            const issue = await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: '🚨 Job Search Automation Failed',
              body: `# Workflow Failure Report
              
              **Run ID**: ${{ needs.prepare.outputs.run_id }}
              **Timestamp**: ${{ needs.prepare.outputs.timestamp }}
              **Mode**: ${{ needs.prepare.outputs.mode }}
              
              ## Stage Results
              - Preparation: ${{ needs.prepare.result }}
              - Extraction: ${{ needs.extract-keywords.result }}
              - Discovery: ${{ needs.trigger-discovery.result }}
              
              [View Workflow Run](${context.payload.repository.html_url}/actions/runs/${context.runId})
              `,
              labels: ['bug', 'job-search-automation', 'workflow-failure']
            });
            
            console.log(`Created issue #${issue.data.number}`);
      
      - name: Final Status
        run: |
          echo "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓"
          echo "                    JOB SEARCH AUTOMATION COMPLETE"
          echo "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛"
          echo ""
          echo "Run ID: ${{ needs.prepare.outputs.run_id }}"
          echo "Status: ${{ job.status }}"
          echo "Matches Found: ${{ needs.extract-keywords.outputs.total_matches }}"
          echo ""
          echo "Next Steps:"
          echo "  1. Review generated config: job-manager-config.yml"
          echo "  2. Check analysis report: keyword_analysis_report.json"
          echo "  3. Monitor discovery workflow for new opportunities"
          echo ""
          echo "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛"
