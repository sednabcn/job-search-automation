    
      - name: Run Job Matcher
        run: |
          echo "üéØ Running multi-platform job matcher..."
    
          # Create reports directory
          mkdir -p reports
    
          # Run analysis using Python script directly
          python3 << 'PYTHON_SCRIPT'
          import sys, os
          from pathlib import Path
          from datetime import datetime
    
          # Add script directory to path
          script_dir = os.path.join(os.getcwd(), '.github', 'scripts')
          sys.path.insert(0, script_dir)
          sys.path.insert(0, '.')
    
          print(f"Python path: {sys.path[:3]}")
          print(f"Current directory: {os.getcwd()}")
          print(f"Script directory: {script_dir}")
    
          try:
            from cv_job_matcher import CVJobMatcher
            print("‚úÖ Successfully imported CVJobMatcher")
          except ImportError as e:
            print(f"‚ùå Failed to import cv_job_matcher.py")
            print(f"Error: {e}")
            print(f"Searched in: {sys.path}")
            sys.exit(1)
    
          # Initialize matcher
          matcher = CVJobMatcher()
    
          
          # Load CV - try multiple locations
          cv_input = '${{ github.event.inputs.cv_file }}'
          cv_file = None
    
          # Priority 1: User-specified file
          if cv_input:
            cv_file = Path(cv_input)
            if not cv_file.exists():
               print(f"‚ö†Ô∏è  Specified CV file not found: {cv_input}")
               cv_file = None
    
          # Priority 2: Look in cv/ directory
          if not cv_file:
             cv_dir = Path('cv')
             if cv_dir.exists():
                cv_files = list(cv_dir.glob('*.txt')) + list(cv_dir.glob('*.md'))
                if cv_files:
                   cv_file = cv_files[0]
                   print(f"‚úì Found CV in cv/ directory: {cv_file}")
    
          # Priority 3: Look in root directory
          if not cv_file:
            root_cv_files = list(Path('.').glob('*.txt')) + list(Path('.').glob('*cv*.md')) + list(Path('.').glob('*resume*.md'))
            if root_cv_files:
              cv_file = root_cv_files[0]
              print(f"‚úì Found CV in root directory: {cv_file}")
    
          # Priority 4: Check if README could serve as CV
          if not cv_file and Path('README.md').exists():
            cv_file = Path('README.md')
            print(f"‚ö†Ô∏è  Using README.md as CV (no dedicated CV file found)")
    
          if not cv_file:
            print("‚ùå No CV file found. Please:")
            print("   1. Create a cv/ directory and add your CV file, or")
            print("   2. Add a CV file to the root directory, or")
            print("   3. Specify a CV file path in the workflow inputs")
            sys.exit(1)
    
      
          cv_text = cv_file.read_text()
          print(f"‚úì Loaded CV from {cv_file}")
    
          # Load discovered jobs
          input_file = Path('discovered_jobs.json')
          if not input_file.exists():
            print(f"‚ùå Input file {input_file} not found")
            sys.exit(1)
    
          import json
          with open(input_file, 'r') as f:
             jobs_data = json.load(f)
    
          print(f"‚úì Loaded {len(jobs_data)} jobs from {input_file}")
    
          # Process each job
          threshold = float('${{ github.event.inputs.match_threshold }}' or '75')
          matched_jobs = []
    
          print(f"\nüîç Analyzing jobs with threshold {threshold}%...\n")
    
          for idx, job in enumerate(jobs_data, 1):
             job_text = f"{job.get('title', '')} {job.get('description', '')} {job.get('requirements', '')}"
        
          # Run analysis
          result = matcher.analyze_job(cv_text, job_text)
        
          # Add match score to job data
          job['match_score'] = result.get('overall_score', 0)
          job['match_details'] = result
        
          # Filter by threshold
          if job['match_score'] >= threshold:
            matched_jobs.append(job)
            print(f"‚úÖ Job {idx}/{len(jobs_data)}: {job.get('title')} - {job['match_score']}%")
          else:
            print(f"‚è≠Ô∏è  Job {idx}/{len(jobs_data)}: {job.get('title')} - {job['match_score']}% (below threshold)")
    
          # Save matched jobs
          output_file = Path('matched_jobs.json')
          with open(output_file, 'w') as f:
            json.dump(matched_jobs, f, indent=2)
    
          print(f"\n‚úÖ {len(matched_jobs)} jobs matched (threshold: {threshold}%)")
          print(f"‚úÖ Results saved to {output_file}")
    
          # Generate summary report
          report_lines = [
          "="*80,
          "JOB MATCHING SUMMARY",
          "="*80,
          f"Total jobs analyzed: {len(jobs_data)}",
          f"Jobs matched: {len(matched_jobs)}",
          f"Match threshold: {threshold}%",
          f"Match rate: {len(matched_jobs)/len(jobs_data)*100:.1f}%",
          "",
          "TOP MATCHES:",
          "-"*80
          ]
    
          # Sort by match score and show top 10
          top_matches = sorted(matched_jobs, key=lambda x: x['match_score'], reverse=True)[:10]
          for job in top_matches:
            report_lines.append(f"{job['match_score']}% - {job.get('title')} at {job.get('company', 'Unknown')}")
            report_lines.append(f"       {job.get('location', 'Location unknown')}")
            report_lines.append("")
    
          report = "\n".join(report_lines)
    
          # Save report
          report_file = Path('reports') / f'matching_summary_{datetime.now().strftime("%Y%m%d_%H%M%S")}.txt'
          report_file.write_text(report)
    
          print("\n" + report)
          PYTHON_SCRIPT
      
