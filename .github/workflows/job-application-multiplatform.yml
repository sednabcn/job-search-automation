name: Multi-Platform Job Application System

on:
  schedule:
    # Check for campaigns every 6 hours
    - cron: "0 */6 * * *"
  
  workflow_dispatch:
    inputs:
      campaign_file:
        description: 'Specific campaign file to run (optional)'
        required: false
        type: string
      force_run:
        description: 'Force run even if schedule not met'
        required: false
        type: boolean
        default: false
      dry_run:
        description: 'Simulate without actually applying'
        required: false
        type: boolean
        default: false

      enable_scoring:
        description: 'Enable job scoring'
        required: false
        type: boolean
        default: true
      
      min_score_threshold:
        description: 'Minimum job score (0-100)'
        required: false
        type: number
        default: 70
      
      generate_cover_letters:
        description: 'Generate AI cover letters'
        required: false
        type: boolean
        default: false
      
      max_cover_letters:
        description: 'Max cover letters to generate'
        required: false
        type: number
        default: 10


permissions:
  contents: write
  issues: write

env:
  PYTHON_VERSION: '3.11'
  CAMPAIGNS_DIR: 'scheduled-campaigns'
  TRACKING_DIR: 'job_search'
  SENT_LOG_DIR: 'sent-log'
  ENABLE_SCORING: ${{ github.event.inputs.enable_scoring || 'true' }}
  MIN_SCORE: ${{ github.event.inputs.min_score_threshold || 70 }}
  ENABLE_AI: ${{ github.event.inputs.generate_cover_letters || 'false' }}
  MAX_AI_LETTERS: ${{ github.event.inputs.max_cover_letters || 10 }}


jobs:
  scan-campaigns:
    name: Scan and Process Campaigns
    runs-on: ubuntu-latest
    timeout-minutes: 45
    
    outputs:
      campaigns_found: ${{ steps.scan.outputs.campaigns_found }}
      campaigns_to_run: ${{ steps.scan.outputs.campaigns_to_run }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 1
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4 pandas python-dateutil pytz
      
      - name: Ensure directory structure
        run: |
          mkdir -p $CAMPAIGNS_DIR
          mkdir -p $TRACKING_DIR/{applications,linkedin,indeed,reed,glassdoor}
          mkdir -p $SENT_LOG_DIR
          mkdir -p cv cover_letter letter contacts
          
          # Initialize tracking files
          for file in applications linkedin_targets indeed_applications reed_applications glassdoor_applications; do
            if [ ! -f "$TRACKING_DIR/${file}.json" ]; then
              echo "[]" > "$TRACKING_DIR/${file}.json"
            fi
          done
      
      - name: Scan campaigns and determine execution
        id: scan
        run: |
          python3 << 'PYTHON_SCRIPT'
          import sys
          import os
          import json
          from pathlib import Path
          from datetime import datetime, timedelta
          import pytz
          
          campaigns_dir = Path("${{ env.CAMPAIGNS_DIR }}")
          force_run = "${{ github.event.inputs.force_run }}" == "true"
          specific_campaign = "${{ github.event.inputs.campaign_file }}"
          
          print("=" * 70)
          print("üîç MULTI-PLATFORM JOB APPLICATION CAMPAIGN SCANNER")
          print("=" * 70)
          
          if not campaigns_dir.exists():
              print(f"‚ùå Campaigns directory not found: {campaigns_dir}")
              sys.exit(1)
          
          # Find all campaign JSON files
          campaign_files = list(campaigns_dir.glob("*.json"))
          
          if specific_campaign:
              campaign_files = [f for f in campaign_files if f.name == specific_campaign]
          
          print(f"\nüìÇ Found {len(campaign_files)} campaign file(s)")
          
          campaigns_to_run = []
          campaigns_info = []
          
          for campaign_file in campaign_files:
              print(f"\nüìÑ Processing: {campaign_file.name}")
              
              try:
                  with open(campaign_file, 'r') as f:
                      campaign = json.load(f)
                  
                  # Extract campaign info
                  campaign_name = campaign_file.stem
                  send_mode = campaign.get('send', 'immediate').lower()
                  timestamp = campaign.get('timestamp', '')
                  platforms = campaign.get('platform', [])
                  target_jobs = campaign.get('target_jobs', [])
                  locations = campaign.get('Location', [])
                  modes = campaign.get('Mode', [])
                  companies = campaign.get('company', [])
                  
                  print(f"   Name: {campaign_name}")
                  print(f"   Send mode: {send_mode}")
                  print(f"   Platforms: {', '.join(platforms)}")
                  print(f"   Target jobs: {len(target_jobs)}")
                  print(f"   Locations: {', '.join(locations)}")
                  
                  # Determine if campaign should run
                  should_run = force_run
                  reason = "Force run enabled"
                  
                  if not force_run:
                      now = datetime.now(pytz.UTC)
                      
                      if send_mode == 'immediate' or send_mode == 'now':
                          should_run = True
                          reason = "Immediate execution"
                      
                      elif send_mode == 'tomorrow':
                          # Check if timestamp is tomorrow
                          if timestamp:
                              try:
                                  target_time = datetime.strptime(timestamp, '%m/%d/%Y:%H:%M:%S')
                                  target_time = pytz.UTC.localize(target_time)
                                  tomorrow = now + timedelta(days=1)
                                  
                                  if target_time.date() == tomorrow.date():
                                      should_run = True
                                      reason = f"Scheduled for tomorrow at {target_time.strftime('%H:%M')}"
                              except:
                                  pass
                      
                      elif send_mode == 'each_day' or send_mode == 'daily':
                          should_run = True
                          reason = "Daily execution"
                      
                      elif send_mode == 'each_week' or send_mode == 'weekly':
                          # Run on Mondays
                          if now.weekday() == 0:
                              should_run = True
                              reason = "Weekly execution (Monday)"
                      
                      elif send_mode.startswith('cron'):
                          # Simple cron support - run during scheduled times
                          should_run = True
                          reason = "Cron schedule"
                      
                      elif send_mode.startswith('delay'):
                          # Check if delay period has passed
                          # Format: "delay 2 hours", "delay 1 day"
                          should_run = False
                          reason = "Delay period not met"
                      
                      elif timestamp:
                          # Check specific timestamp
                          try:
                              target_time = datetime.strptime(timestamp, '%m/%d/%Y:%H:%M:%S')
                              target_time = pytz.UTC.localize(target_time)
                              
                              if now >= target_time:
                                  should_run = True
                                  reason = f"Scheduled time reached: {timestamp}"
                          except Exception as e:
                              print(f"   ‚ö†Ô∏è Invalid timestamp format: {e}")
                  
                  campaign_info = {
                      'file': campaign_file.name,
                      'name': campaign_name,
                      'send_mode': send_mode,
                      'platforms': platforms,
                      'should_run': should_run,
                      'reason': reason,
                      'config': campaign
                  }
                  
                  campaigns_info.append(campaign_info)
                  
                  if should_run:
                      campaigns_to_run.append(campaign_info)
                      print(f"   ‚úÖ Will run: {reason}")
                  else:
                      print(f"   ‚è∏Ô∏è Skipped: {reason}")
              
              except Exception as e:
                  print(f"   ‚ùå Error loading campaign: {e}")
                  continue
          
          print(f"\n{'=' * 70}")
          print(f"üìä SCAN SUMMARY")
          print(f"{'=' * 70}")
          print(f"Total campaigns: {len(campaigns_info)}")
          print(f"Campaigns to run: {len(campaigns_to_run)}")
          
          # Save results for next job
          output_file = Path('campaign_execution_plan.json')
          with open(output_file, 'w') as f:
              json.dump({
                  'campaigns_to_run': campaigns_to_run,
                  'scan_time': datetime.now(pytz.UTC).isoformat(),
                  'force_run': force_run
              }, f, indent=2)
          
          # Set outputs
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"campaigns_found={len(campaigns_info)}\n")
              f.write(f"campaigns_to_run={len(campaigns_to_run)}\n")
          
          print(f"\n‚úÖ Scan complete - execution plan saved")
          PYTHON_SCRIPT

      - name: Debug campaign scan results
        run: |
          echo "================================"
          echo "DEBUG: Campaign Scan Results"
          echo "================================"
          echo "Campaigns found: ${{ steps.scan.outputs.campaigns_found }}"
          echo "Campaigns to run: ${{ steps.scan.outputs.campaigns_to_run }}"
          echo ""
          echo "Execution plan contents:"
          cat campaign_execution_plan.json || echo "‚ùå No execution plan found"
          echo ""
          echo "Campaign files in directory:"
          ls -la ${{ env.CAMPAIGNS_DIR }}/ || echo "‚ùå No campaigns directory"
          echo "================================"
          
      - name: Upload execution plan
        uses: actions/upload-artifact@v4
        with:
          name: campaign-execution-plan
          path: campaign_execution_plan.json
          retention-days: 1

  execute-campaigns:
    name: Execute Job Applications
    needs: scan-campaigns
    if: needs.scan-campaigns.outputs.campaigns_to_run > 0
    runs-on: ubuntu-latest
    timeout-minutes: 60
    
    steps:
      - name: Debug execution prerequisites
        run: |
          echo "================================"
          echo "DEBUG: Execution Job Started"
          echo "================================"
          echo "Campaigns to run: ${{ needs.scan-campaigns.outputs.campaigns_to_run }}"
          echo "Force run: ${{ github.event.inputs.force_run }}"
          echo "Dry run: ${{ github.event.inputs.dry_run }}"
          echo "Specific campaign: ${{ github.event.inputs.campaign_file }}"
          echo "================================"
      
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4 pandas python-dateutil pytz
      
      - name: Download execution plan
        uses: actions/download-artifact@v4
        with:
          name: campaign-execution-plan
      
      - name: Debug execution environment
        run: |
          echo "================================"
          echo "DEBUG: Execution Environment"
          echo "================================"
          
          # Check campaign plan
          echo "üìã Campaign Execution Plan:"
          cat campaign_execution_plan.json | python3 -m json.tool
          
          echo ""
          echo "üìÇ Directory Structure:"
          ls -la .github/scripts/ 2>/dev/null || echo "‚ö†Ô∏è No .github/scripts/ directory"
          
          echo ""
          echo "üìÑ Available Python modules:"
          find .github/scripts/ -name "*.py" 2>/dev/null || echo "‚ö†Ô∏è No Python scripts found"
          
          echo ""
          echo "üìÅ Campaign files:"
          ls -la scheduled-campaigns/*.json 2>/dev/null || echo "‚ö†Ô∏è No campaign files"
          
          echo ""
          echo "üìù Contacts directory:"
          ls -la contacts/ 2>/dev/null || echo "‚ö†Ô∏è No contacts directory"
          
          echo ""
          echo "üìÑ CV directory:"
          ls -la cv/ 2>/dev/null || echo "‚ö†Ô∏è No CV directory"
          
          echo ""
          echo "üîç Python path check:"
          python3 -c "import sys; print('\n'.join(sys.path))"
          
          echo "================================"
      
      - name: Execute campaigns
        id: execute
        env:
          DRY_RUN: ${{ github.event.inputs.dry_run }}
        run: |
          python3 << 'PYTHON_SCRIPT'
          import sys
          import os
          import json
          import csv
          from pathlib import Path
          from datetime import datetime
          import traceback
          
          # Add script paths
          sys.path.insert(0, '.github/scripts')
          
          # Try to import platform modules
          platforms_available = {}
          
          try:
              from linkedin_advanced_networking import AdvancedLinkedInNetworking
              platforms_available['linkedin'] = AdvancedLinkedInNetworking
              print("‚úÖ LinkedIn module loaded")
          except ImportError:
              try:
                  from linkedin_automation import LinkedInAutomation
                  platforms_available['linkedin'] = LinkedInAutomation
                  print("‚úÖ LinkedIn automation module loaded")
              except ImportError:
                  print("‚ö†Ô∏è LinkedIn modules not available")
          
          try:
              from indeed_scraper import IndeedScraper
              platforms_available['indeed'] = IndeedScraper
              print("‚úÖ Indeed module loaded")
          except ImportError:
              print("‚ö†Ô∏è Indeed module not available")
          
          try:
              from reed_scraper import ReedScraper
              platforms_available['reed'] = ReedScraper
              print("‚úÖ Reed module loaded")
          except ImportError:
              print("‚ö†Ô∏è Reed module not available")
          
          try:
              from glassdoor_automation import GlassdoorAutomation
              platforms_available['glassdoor'] = GlassdoorAutomation
              print("‚úÖ Glassdoor module loaded")
          except ImportError:
              print("‚ö†Ô∏è Glassdoor module not available")
          
          print("\n" + "=" * 70)
          print("üöÄ EXECUTING MULTI-PLATFORM JOB APPLICATIONS")
          print("=" * 70)
          
          # Load execution plan
          with open('campaign_execution_plan.json', 'r') as f:
              plan = json.load(f)
          
          campaigns = plan['campaigns_to_run']
          dry_run = "${{ github.event.inputs.dry_run }}" == "true"
          
          print(f"\nMode: {'DRY RUN' if dry_run else 'LIVE'}")
          print(f"Campaigns to execute: {len(campaigns)}\n")
          
          # Execution tracking
          execution_results = {
              'start_time': datetime.now().isoformat(),
              'campaigns': [],
              'total_applications': 0,
              'successful': 0,
              'failed': 0,
              'platforms': {}
          }
          
          for campaign_info in campaigns:
              campaign_name = campaign_info['name']
              config = campaign_info['config']
              
              print(f"\n{'=' * 70}")
              print(f"üìã CAMPAIGN: {campaign_name}")
              print(f"{'=' * 70}")
              
              campaign_result = {
                  'name': campaign_name,
                  'platforms': [],
                  'applications': 0,
                  'successful': 0,
                  'failed': 0,
                  'errors': []
              }
              
              # Load CV and documents
              cv_dir = config.get('cv_dir', 'cv')
              cv_file = config.get('cv_file', 'my_cv.txt')
              cv_path = Path(cv_dir) / cv_file
              
              cover_letter_dir = config.get('cover_letter_dir', 'cover_letter')
              cover_letter_file = config.get('cover_letter_file', 'my_cover.txt')
              cover_letter_path = Path(cover_letter_dir) / cover_letter_file
              
              # Load contacts
              contacts_dir = config.get('target_contacts_dir', 'contacts')
              contacts_file = config.get('target_contacts_file', 'contacts.csv')
              contacts_path = Path(contacts_dir) / contacts_file
              
              contacts = []
              if contacts_path.exists():
                  try:
                      with open(contacts_path, 'r', encoding='utf-8') as f:
                          reader = csv.DictReader(f)
                          contacts = list(reader)
                      print(f"‚úÖ Loaded {len(contacts)} contacts from {contacts_path}")
                  except Exception as e:
                      print(f"‚ö†Ô∏è Error loading contacts: {e}")
              
              # Get campaign parameters
              platforms = config.get('platform', [])
              target_jobs = config.get('target_jobs', [])
              locations = config.get('Location', [])
              modes = config.get('Mode', [])
              companies = config.get('company', [])
              notification_email = config.get('notification_to_user', '')
              
              print(f"üìä Campaign Parameters:")
              print(f"   Target jobs: {', '.join(target_jobs)}")
              print(f"   Locations: {', '.join(locations)}")
              print(f"   Modes: {', '.join(modes)}")
              print(f"   Platforms: {', '.join(platforms)}")
              if companies:
                  print(f"   Target companies: {', '.join(companies)}")
              
              # Process each platform
              for platform in platforms:
                  platform_lower = platform.lower()
                  print(f"\nüéØ Platform: {platform}")
                  
                  platform_result = {
                      'platform': platform,
                      'applications': 0,
                      'successful': 0,
                      'failed': 0
                  }
                  
                  try:
                      if platform_lower == 'linkedin':
                          if 'linkedin' in platforms_available:
                              print("   Processing LinkedIn applications...")
                              
                              linkedin_module = platforms_available['linkedin']()
                              
                              # Add connection targets
                              for contact in contacts[:10]:  # Limit for safety
                                  try:
                                      if hasattr(linkedin_module, 'add_connection_target'):
                                          result = linkedin_module.add_connection_target(
                                              profile_url=contact.get('profile_url', ''),
                                              name=contact.get('name', ''),
                                              company=contact.get('company', ''),
                                              position=contact.get('position', ''),
                                              industry=contact.get('industry', 'tech'),
                                              priority='high'
                                          )
                                          if result.get('success'):
                                              platform_result['successful'] += 1
                                              platform_result['applications'] += 1
                                          else:
                                              platform_result['failed'] += 1
                                      
                                      if not dry_run and hasattr(linkedin_module, 'save_data'):
                                          linkedin_module.save_data()
                                  
                                  except Exception as e:
                                      print(f"      ‚ö†Ô∏è Error with contact {contact.get('name')}: {e}")
                                      platform_result['failed'] += 1
                              
                              print(f"   ‚úÖ LinkedIn: {platform_result['successful']} connections queued")
                          else:
                              print("   ‚ö†Ô∏è LinkedIn module not available")
                      
                      elif platform_lower == 'indeed':
                          if 'indeed' in platforms_available:
                              print("   Processing Indeed applications...")
                              
                              indeed_scraper = platforms_available['indeed']()
                              
                              # Search for jobs
                              for job_title in target_jobs:
                                  for location in locations:
                                      try:
                                          jobs = indeed_scraper.search_jobs(
                                              job_title=job_title,
                                              location=location,
                                              max_results=10
                                          )
                                          
                                          print(f"      Found {len(jobs)} jobs for '{job_title}' in {location}")
                                          
                                          # Filter by mode and company
                                          filtered_jobs = jobs
                                          
                                          if modes:
                                              # Filter by remote/hybrid etc
                                              mode_keywords = [m.lower() for m in modes]
                                              filtered_jobs = [
                                                  j for j in filtered_jobs
                                                  if any(kw in str(j.get('attributes', [])).lower() 
                                                        for kw in mode_keywords)
                                              ]
                                          
                                          if companies:
                                              filtered_jobs = [
                                                  j for j in filtered_jobs
                                                  if j.get('company', '').lower() in 
                                                     [c.lower() for c in companies]
                                              ]
                                          
                                          platform_result['applications'] += len(filtered_jobs)
                                          platform_result['successful'] += len(filtered_jobs)
                                          
                                          print(f"      ‚úÖ {len(filtered_jobs)} jobs after filtering")
                                      
                                      except Exception as e:
                                          print(f"      ‚ö†Ô∏è Error searching Indeed: {e}")
                                          platform_result['failed'] += 1
                              
                              # Save jobs
                              if not dry_run:
                                  indeed_scraper.save_jobs(f'job_search/indeed_jobs_{campaign_name}.json')
                          else:
                              print("   ‚ö†Ô∏è Indeed module not available")
                      
                      elif platform_lower == 'reed':
                          if 'reed' in platforms_available:
                              print("   Processing Reed applications...")
                              # Similar implementation for Reed
                              platform_result['applications'] = 0
                              print("   ‚ÑπÔ∏è Reed implementation pending")
                          else:
                              print("   ‚ö†Ô∏è Reed module not available")
                      
                      elif platform_lower == 'glassdoor':
                          if 'glassdoor' in platforms_available:
                              print("   Processing Glassdoor research...")
                              
                              glassdoor = platforms_available['glassdoor']()
                              
                              # Add companies to research
                              for company in companies:
                                  try:
                                      result = glassdoor.add_company_to_research(
                                          company_name=company,
                                          priority='high',
                                          reason='job_application'
                                      )
                                      
                                      if result.get('success'):
                                          platform_result['successful'] += 1
                                          platform_result['applications'] += 1
                                      else:
                                          platform_result['failed'] += 1
                                  
                                  except Exception as e:
                                      print(f"      ‚ö†Ô∏è Error adding {company}: {e}")
                                      platform_result['failed'] += 1
                              
                              print(f"   ‚úÖ Glassdoor: {platform_result['successful']} companies queued")
                          else:
                              print("   ‚ö†Ô∏è Glassdoor module not available")
                      
                      else:
                          print(f"   ‚ö†Ô∏è Unknown platform: {platform}")
                  
                  except Exception as e:
                      print(f"   ‚ùå Platform error: {e}")
                      traceback.print_exc()
                      campaign_result['errors'].append(f"{platform}: {str(e)}")
                  
                  campaign_result['platforms'].append(platform_result)
                  campaign_result['applications'] += platform_result['applications']
                  campaign_result['successful'] += platform_result['successful']
                  campaign_result['failed'] += platform_result['failed']
              
              execution_results['campaigns'].append(campaign_result)
              execution_results['total_applications'] += campaign_result['applications']
              execution_results['successful'] += campaign_result['successful']
              execution_results['failed'] += campaign_result['failed']
              
              print(f"\n‚úÖ Campaign '{campaign_name}' complete:")
              print(f"   Total: {campaign_result['applications']}")
              print(f"   Successful: {campaign_result['successful']}")
              print(f"   Failed: {campaign_result['failed']}")
          
          execution_results['end_time'] = datetime.now().isoformat()
          execution_results['dry_run'] = dry_run
          
          # Save execution results
          results_file = Path('campaign_execution_results.json')
          with open(results_file, 'w') as f:
              json.dump(execution_results, f, indent=2)
          
          # Save to tracking
          tracking_dir = Path('${{ env.TRACKING_DIR }}')
          timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
          tracking_file = tracking_dir / f'campaign_execution_{timestamp}.json'
          with open(tracking_file, 'w') as f:
              json.dump(execution_results, f, indent=2)
          
          print(f"\n{'=' * 70}")
          print(f"üìä EXECUTION SUMMARY")
          print(f"{'=' * 70}")
          print(f"Total applications: {execution_results['total_applications']}")
          print(f"Successful: {execution_results['successful']}")
          print(f"Failed: {execution_results['failed']}")
          print(f"Mode: {'DRY RUN' if dry_run else 'LIVE'}")
          
          # Set outputs
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"total_applications={execution_results['total_applications']}\n")
              f.write(f"successful={execution_results['successful']}\n")
              f.write(f"failed={execution_results['failed']}\n")
          
          print(f"\n‚úÖ Execution complete!")
          PYTHON_SCRIPT

      - name: Upload execution results
        uses: actions/upload-artifact@v4
        with:
          name: campaign-execution-results-${{ github.run_number }}
          path: |
            campaign_execution_results.json
            job_search/campaign_execution_*.json
          retention-days: 90   
      
      - name: Commit tracking data
        uses: ./.github/actions/safe-git-push
        with:
          commit-message: "üì§ Campaign execution: ${{ steps.execute.outputs.total_applications }} applications - $(date +'%Y-%m-%d %H:%M')"
          files: "job_search/*.json sent-log/"
      
      - name: Create execution summary issue
        if: steps.execute.outputs.total_applications > 0
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            let results = { campaigns: [] };
            if (fs.existsSync('campaign_execution_results.json')) {
              results = JSON.parse(fs.readFileSync('campaign_execution_results.json', 'utf8'));
            }
            
            const totalApps = '${{ steps.execute.outputs.total_applications }}';
            const successful = '${{ steps.execute.outputs.successful }}';
            const failed = '${{ steps.execute.outputs.failed }}';
            const dryRun = '${{ github.event.inputs.dry_run }}' === 'true';
            
            let body = `# Multi-Platform Job Application Summary\n\n`;
            body += `**Execution Mode:** ${dryRun ? 'üß™ DRY RUN' : '‚úÖ LIVE'}\n`;
            body += `**Date:** ${new Date().toISOString().split('T')[0]}\n\n`;
            body += `## Overall Results\n\n`;
            body += `- **Total Applications:** ${totalApps}\n`;
            body += `- **Successful:** ${successful}\n`;
            body += `- **Failed:** ${failed}\n\n`;
            
            if (results.campaigns && results.campaigns.length > 0) {
              body += `## Campaign Details\n\n`;
              
              for (const campaign of results.campaigns) {
                body += `### ${campaign.name}\n\n`;
                body += `- Applications: ${campaign.applications}\n`;
                body += `- Successful: ${campaign.successful}\n`;
                body += `- Failed: ${campaign.failed}\n\n`;
                
                if (campaign.platforms && campaign.platforms.length > 0) {
                  body += `**By Platform:**\n`;
                  for (const platform of campaign.platforms) {
                    body += `- ${platform.platform}: ${platform.successful}/${platform.applications}\n`;
                  }
                  body += `\n`;
                }
                
                if (campaign.errors && campaign.errors.length > 0) {
                  body += `**Errors:**\n`;
                  for (const error of campaign.errors) {
                    body += `- ${error}\n`;
                  }
                  body += `\n`;
                }
              }
            }
            
            body += `\n---\n*Automated by Multi-Platform Job Application System*`;
            
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `üì§ Campaign Execution: ${totalApps} applications submitted`,
              body: body,
              labels: ['job-applications', 'multi-platform', 'automated']
            });
            
              
  score-discovered-jobs:
    name: Score Discovered Jobs
    needs: execute-campaigns
    if: success()
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Download execution results
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          name: campaign-execution-results-${{ github.run_number }}

      
      - name: Score discovered jobs
        run: |
          python3 << 'PYTHON_SCRIPT'
          import sys
          sys.path.insert(0, 'scripts')
          
          try:
              from job_scorer import JobScorer
              
              scorer = JobScorer('contacts/profile.json')
              
              # Load jobs from tracking
              import json
              from pathlib import Path
              
              jobs_file = Path('job_search/applications.json')
              if jobs_file.exists():
                  with open(jobs_file) as f:
                      jobs = json.load(f)
                  
                  print(f"üéØ Scoring {len(jobs)} jobs...")
                  
                  scored_jobs = []
                  high_quality = 0
                  
                  for job in jobs:
                      score_result = scorer.score_job(job)
                      job['score'] = score_result['score']
                      job['score_reasons'] = score_result['reasons']
                      job['verdict'] = score_result['verdict']
                      
                      scored_jobs.append(job)
                      
                      if score_result['score'] >= 70:
                          high_quality += 1
                  
                  # Save scored jobs
                  with open('job_search/scored_jobs.json', 'w') as f:
                      json.dump(scored_jobs, f, indent=2)
                  
                  print(f"‚úÖ Scored {len(scored_jobs)} jobs")
                  print(f"üéØ {high_quality} high-quality matches (score ‚â•70)")
              
          except ImportError:
              print("‚ö†Ô∏è Job scorer not available - skipping scoring")
          PYTHON_SCRIPT

      
      - name: Score jobs from all platforms
        id: scoring
        run: |
          python3 << 'PYTHON_SCRIPT'
          import json
          import subprocess
          from pathlib import Path
          from datetime import datetime
          
          print("=" * 70)
          print("üéØ SCORING DISCOVERED JOBS")
          print("=" * 70)
          
          tracking_dir = Path('job_search')
          cv_path = 'cv/my_cv.txt'
          prefs_path = 'configs/scoring_preferences.json'
          min_score = 70
          
          platforms = ['linkedin', 'indeed', 'reed', 'glassdoor']
          all_scored_jobs = []
          
          for platform in platforms:
              jobs_file = tracking_dir / f'{platform}_jobs.json'
              
              if not jobs_file.exists():
                  print(f"‚è≠Ô∏è  No {platform} jobs found")
                  continue
              
              print(f"\nüìä Scoring {platform} jobs...")
              
              # Score jobs
              output_file = tracking_dir / f'{platform}_jobs_scored.json'
              
              cmd = [
                  'python3', 'scripts/job_scorer.py',
                  '--cv', cv_path,
                  '--jobs', str(jobs_file),
                  '--output', str(output_file),
                  '--preferences', prefs_path,
                  '--min-score', str(min_score)
              ]
              
              try:
                  result = subprocess.run(cmd, capture_output=True, text=True)
                  print(result.stdout)
                  
                  # Load scored results
                  if output_file.exists():
                      with open(output_file, 'r') as f:
                          scored_data = json.load(f)
                          all_scored_jobs.extend(scored_data['jobs'])
                      print(f"‚úÖ {platform}: {scored_data['filtered_jobs']} high-quality jobs")
                  
              except Exception as e:
                  print(f"‚ö†Ô∏è  Error scoring {platform} jobs: {e}")
          
          # Combine and rank all jobs
          all_scored_jobs.sort(key=lambda x: x['total_score'], reverse=True)
          
          # Save combined results
          combined_file = tracking_dir / 'matched_jobs_scored.json'
          with open(combined_file, 'w') as f:
              json.dump({
                  'scored_at': datetime.now().isoformat(),
                  'total_jobs': len(all_scored_jobs),
                  'min_score_threshold': min_score,
                  'top_matches': all_scored_jobs[:50],  # Top 50
                  'all_jobs': all_scored_jobs
              }, f, indent=2)
          
          print(f"\nüíæ Combined scored jobs saved: {combined_file}")
          print(f"üìä Total high-quality jobs across all platforms: {len(all_scored_jobs)}")
          
          # Set outputs
          import os
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"total_scored={len(all_scored_jobs)}\n")
              f.write(f"top_score={all_scored_jobs[0]['total_score'] if all_scored_jobs else 0}\n")
          
          print("=" * 70)
          PYTHON_SCRIPT
      
      - name: Upload scored jobs
        uses: actions/upload-artifact@v4
        with:
          name: scored-jobs-${{ github.run_number }}
          path: |
            job_search/*_scored.json
            job_search/matched_jobs_scored.json
          retention-days: 90

      - name: Commit scored jobs
        uses: ./.github/actions/safe-git-push
        with:
          commit-message: "üéØ Scored jobs: ${{ steps.scoring.outputs.total_scored }} matches - $(date +'%Y-%m-%d %H:%M')"
          files: "job_search/*_scored.json"
      
      - name: Create application packages
        id: create_packages
        run: |
          python3 << 'PYTHON_SCRIPT'
          import sys
          import json
          from pathlib import Path
          sys.path.insert(0, '.github/scripts')
          
          try:
              from application_prefiller import ApplicationPrefiller
              from application_tracker import ApplicationTracker
              
              print("üì¶ Creating application packages...")
              
              # Load execution results
              with open('campaign_execution_results.json', 'r') as f:
                  results = json.load(f)
              
              prefiller = ApplicationPrefiller()
              tracker = ApplicationTracker()
              
              packages_created = 0
              
              # Load platform-specific job data
              for campaign in results['campaigns']:
                  campaign_config = campaign.get('config', {})
                  platforms = campaign_config.get('platform', [])
                  
                  for platform in platforms:
                      platform_lower = platform.lower()
                      
                      # Load jobs from platform-specific files
                      jobs_file = Path(f'job_search/{platform_lower}_jobs_{campaign["name"]}.json')
                      
                      if jobs_file.exists():
                          with open(jobs_file, 'r') as f:
                              jobs = json.load(f)
                          
                          print(f"\nüéØ Processing {len(jobs)} jobs from {platform}")
                          
                          for job in jobs[:5]:  # Limit for safety
                              try:
                                  # Create application package
                                  package_dir = prefiller.create_application_package(
                                      job_posting=job,
                                      cv_path=campaign_config.get('cv_dir', 'cv') + '/' + 
                                             campaign_config.get('cv_file', 'my_cv.txt'),
                                      cover_letter_path=campaign_config.get('cover_letter_dir', 'cover_letter') + '/' +
                                                       campaign_config.get('cover_letter_file', 'my_cover.txt'),
                                      platform=platform_lower
                                  )
                                  
                                  # Add to tracker
                                  tracker.add_application(
                                      job_id=job.get('id', f"{platform_lower}_{packages_created}"),
                                      job_data=job,
                                      platform=platform_lower,
                                      package_path=str(package_dir)
                                  )
                                  
                                  # Update status to package_created
                                  tracker.update_status(
                                      job_id=job.get('id'),
                                      new_status='package_created',
                                      notes=f'Application package created at {package_dir}'
                                  )
                                  
                                  packages_created += 1
                                  
                              except Exception as e:
                                  print(f"‚ö†Ô∏è Error creating package for job: {e}")
                                  continue
              
              print(f"\n‚úÖ Created {packages_created} application packages")
              
              # Set output
              import os
              with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                  f.write(f"packages_created={packages_created}\n")
              
          except Exception as e:
              print(f"‚ùå Error in package creation: {e}")
              import traceback
              traceback.print_exc()
          PYTHON_SCRIPT
            
  track-application-status:
    name: Track Application Status
    runs-on: ubuntu-latest
    needs: execute-campaigns
    if: success()
    outputs:
      packages_created: ${{ steps.create_packages.outputs.packages_created }}
      
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

    
      - name: Download campaign execution results
        uses: actions/download-artifact@v4
        with:
          name: campaign-execution-results-${{ github.run_number }}
    
          
      - name: Verify campaign results
        run: |
          if [ ! -f "campaign_execution_results.json" ]; then
             echo "‚ö†Ô∏è  Campaign results not found, creating empty results"
             cat > campaign_execution_results.json << 'EOF'
          {
          "campaigns": [],
          "total_applications": 0,
          "successful": 0,
          "failed": 0,
          "start_time": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
          "end_time": "$(date -u +%Y-%m-%dT%H:%M:%SZ)"
          }
          EOF
          fi

          
          echo "üìÑ Campaign results:"
          cat campaign_execution_results.json | python3 -m json.tool
    
      - name: Update application statuses
        run: |
           python3 .github/scripts/github_actions_status_updater.py \
            --campaign-results campaign_execution_results.json \
            --data-dir ${{ env.TRACKING_DIR }} \
            --output status_update_results.json

      - name: Commit status updates
        uses: ./.github/actions/safe-git-push
        with:
          commit-message: "üìä Updated application statuses from campaign"
          files: "${{ env.TRACKING_DIR }}/applications.json ${{ env.TRACKING_DIR }}/analytics.json"
      
  # ========================================
  # NEW: FOLLOW-UP REMINDER CREATION
  # ========================================
  create-followup-reminders:
    name: Create Follow-up Reminders
    runs-on: ubuntu-latest
    needs: [execute-campaigns, track-application-status]
    if: success()
    
    outputs:
      reminders_created: ${{ steps.reminders.outputs.count }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

       
      - name: Download campaign execution results
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          name: campaign-execution-results-${{ github.run_number }}
    
      - name: Verify campaign results exist
        run: |
          if [ ! -f "campaign_execution_results.json" ]; then
            echo "‚ö†Ô∏è  Creating placeholder campaign results"
            echo '{"campaigns":[],"total_applications":0}' > campaign_execution_results.json
          fi
          
      - name: Create follow-up reminders
        id: reminders
        run: |
          python3 .github/scripts/github_actions_followup_manager.py \
            --mode create \
            --campaign-results campaign_execution_results.json \
            --data-dir ${{ env.TRACKING_DIR }} \
            --output reminder_creation_results.json
          
          COUNT=$(jq '.reminders_created' reminder_creation_results.json)
          echo "count=$COUNT" >> $GITHUB_OUTPUT

      - name: Commit reminders
        uses: ./.github/actions/safe-git-push
        with:
          commit-message: "‚è∞ Created ${{ steps.reminders.outputs.count }} follow-up reminders"
          files: "${{ env.TRACKING_DIR }}/applications.json ${{ env.TRACKING_DIR }}/reports/ ${{ env.TRACKING_DIR }}/campaign_reminders.ics"
      
      - name: Upload reminder calendar
        uses: actions/upload-artifact@v4
        with:
          name: campaign-reminders-calendar-${{ github.run_number }}
          path: ${{ env.TRACKING_DIR }}/campaign_reminders.ics
          retention-days: 90


          
      - name: Generate tracker report
        run: |
          python3 << 'PYTHON_SCRIPT'
          import sys
          sys.path.insert(0, '.github/scripts')
          
          from application_tracker import ApplicationTracker
          from pathlib import Path
          
          tracker = ApplicationTracker()
          
          # Generate markdown report
          report = tracker.generate_report(output_format='markdown')
          
          # Save report
          reports_dir = Path('job_search/reports')
          reports_dir.mkdir(parents=True, exist_ok=True)
          
          report_file = reports_dir / 'application_tracker_report.md'
          with open(report_file, 'w') as f:
              f.write(report)
          
          print(f"‚úÖ Tracker report generated: {report_file}")
          
          # Export to CSV
          tracker.export_to_csv('applications_export.csv')
          PYTHON_SCRIPT
      
      - name: Generate AI cover letters for top matches
        if: steps.execute.outputs.successful >= 5
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          python3 << 'PYTHON_SCRIPT'
          import sys
          sys.path.insert(0, 'scripts')
          
          try:
              from cover_letter_generator import CoverLetterGenerator
              import json
              from pathlib import Path
              
              # Check for API key
              api_key = "${{ secrets.OPENAI_API_KEY }}"
              if not api_key:
                  print("‚ö†Ô∏è No OpenAI API key - skipping cover letter generation")
                  sys.exit(0)
              
              generator = CoverLetterGenerator(api_key)
              
              # Load scored jobs
              scored_file = Path('job_search/scored_jobs.json')
              if scored_file.exists():
                  with open(scored_file) as f:
                      jobs = json.load(f)
                  
                  # Filter high-score jobs
                  high_score_jobs = [j for j in jobs if j.get('score', 0) >= 75][:10]
                  
                  print(f"üìù Generating cover letters for {len(high_score_jobs)} top jobs...")
                  
                  # Load CV
                  cv_path = Path('cv/my_cv.txt')
                  cv_content = cv_path.read_text() if cv_path.exists() else ""
                  
                  letters_generated = 0
                  for job in high_score_jobs:
                      try:
                          letter = generator.generate(job, cv_content, job)
                          saved_path = generator.save_cover_letter(letter, job['id'])
                          letters_generated += 1
                          print(f"   ‚úÖ {job['company']} - {job['title']}")
                      except Exception as e:
                          print(f"   ‚ö†Ô∏è Error for {job.get('company')}: {e}")
                  
                  print(f"\n‚úÖ Generated {letters_generated} cover letters")
              
          except ImportError:
              print("‚ö†Ô∏è Cover letter generator not available")
          except Exception as e:
              print(f"‚ö†Ô∏è Cover letter generation failed: {e}")
          PYTHON_SCRIPT

      - name: Generate email report
        run: |
          python3 .github/scripts/generate_email_report.py \
          --template .github/templates/email-campaign-report.html \
          --output email-body.html \
          --total-applications ${{ steps.execute.outputs.total_applications || '0' }} \
          --successful ${{ steps.execute.outputs.successful || '0' }} \
          --failed ${{ steps.execute.outputs.failed || '0' }} \
          --high-quality-matches ${{ needs.score-discovered-jobs.outputs.total_scored || '0' }} \
          --top-score ${{ needs.score-discovered-jobs.outputs.top_score || '0' }} \
          --packages-created ${{ steps.create_packages.outputs.packages_created || '0' }} \
          --reminders-created ${{ needs.create-followup-reminders.outputs.reminders_created || '0' }} \
          --github-server ${{ github.server_url }} \
          --repository ${{ github.repository }} \
          --run-id ${{ github.run_id }}
          
      - name: Send email with generated report
        uses: dawidd6/action-send-mail@v3
        with:
          server_address: smtp.gmail.com
          server_port: 587
          username: ${{ secrets.SMTP_USER }}
          password: ${{ secrets.SMTP_PASS }}
          subject: "üì§ Campaign Report: ${{ steps.execute.outputs.total_applications }} applications"
          to: ${{ secrets.NOTIFICATION_EMAIL }}
          from: Job Search Automation <${{ secrets.SMTP_USER }}>
          html_body: file://email-body.html
          attachments: job_search/matched_jobs_scored.json
    
#========================================
# MODIFIED: ENHANCED EMAIL NOTIFICATION
# ========================================
  send-enhanced-notification:
    name: Send Enhanced Email Notification
    runs-on: ubuntu-latest
    needs: [execute-campaigns, track-application-status, create-followup-reminders, score-discovered-jobs]
    if: success()
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
  
      - name: Download artifacts
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          name: campaign-reminders-calendar-${{ github.run_number }}

          
      - name: Generate email from template
        run: |
          python3 .github/scripts/generate_email_report.py \
          --template .github/templates/campaign-email.html \
          --output email-body.html \
          --total-applications ${{ needs.execute-campaigns.outputs.total_applications || '0' }} \
          --successful ${{ needs.execute-campaigns.outputs.successful || '0' }} \
          --failed ${{ needs.execute-campaigns.outputs.failed || '0' }} \
          --high-quality-matches ${{ needs.score-discovered-jobs.outputs.total_scored || '0' }} \
          --top-score ${{ needs.score-discovered-jobs.outputs.top_score || '0' }} \
          --packages-created ${{ needs.track-application-status.outputs.packages_created || '0' }} \
          --reminders-created ${{ needs.create-followup-reminders.outputs.reminders_created || '0' }} \
          --github-server ${{ github.server_url }} \
          --repository ${{ github.repository }} \
          --run-id ${{ github.run_id }}

      - name: Send comprehensive campaign email
        uses: dawidd6/action-send-mail@v3
        with:
          server_address: smtp.gmail.com
          server_port: 587
          username: ${{ secrets.SMTP_USER }}
          password: ${{ secrets.SMTP_PASS }}
          subject: "üöÄ Campaign Complete: ${{ steps.execute.outputs.total_applications }} applications"
          to: ${{ secrets.NOTIFICATION_EMAIL }}
          from: Job Search Automation <${{ secrets.SMTP_USER }}>
          html_body: file://email-body.html
          attachments: |
            job_search/matched_jobs_scored.json
            ${{ env.TRACKING_DIR }}/campaign_reminders.ics
            ${{ env.TRACKING_DIR }}/reports/initial_followup_report.txt
            
  generate-report:
    name: Generate Campaign Report
    needs: execute-campaigns
    if: always()
    runs-on: ubuntu-latest
    timeout-minutes: 10
    outputs:
      total_applications: ${{ steps.execute.outputs.total_applications }}
      successful: ${{ steps.execute.outputs.successful }}
      failed: ${{ steps.execute.outputs.failed }}
      
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Download execution results
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          name: campaign-execution-results-${{ github.run_number }}

      - name: Generate Pipeline Report
        run: python3 .github/scripts/generate_pipeline_report.py
      
      - name: Generate comprehensive report
        run: |
          python3 << 'PYTHON_SCRIPT'
          import json
          from pathlib import Path
          from datetime import datetime
          from collections import defaultdict
          
          print("=" * 70)
          print("üìä GENERATING COMPREHENSIVE CAMPAIGN REPORT")
          print("=" * 70)
          
          tracking_dir = Path('job_search')
          
          # Load execution results
          results = {'campaigns': [], 'total_applications': 0}
          results_file = Path('campaign_execution_results.json')
          
          if results_file.exists():
              with open(results_file, 'r') as f:
                  results = json.load(f)
          
          # Load historical data
          def load_json(filename):
              filepath = tracking_dir / filename
              if filepath.exists():
                  try:
                      with open(filepath, 'r') as f:
                          return json.load(f)
                  except:
                      pass
              return []
          
          all_applications = load_json('applications.json')
          linkedin_targets = load_json('linkedin_targets.json')
          
          # Calculate statistics
          stats_by_platform = defaultdict(lambda: {'total': 0, 'successful': 0, 'failed': 0})
          
          for campaign in results.get('campaigns', []):
              for platform_result in campaign.get('platforms', []):
                  platform = platform_result['platform'].lower()
                  stats_by_platform[platform]['total'] += platform_result['applications']
                  stats_by_platform[platform]['successful'] += platform_result['successful']
                  stats_by_platform[platform]['failed'] += platform_result['failed']
          
          # Generate markdown report
          report = f"""# Multi-Platform Job Application Report
          
          ## Execution Summary
          **Date:** {datetime.now().strftime('%Y-%m-%d %H:%M UTC')}  
          **Total Applications:** {results.get('total_applications', 0)}  
          **Successful:** {results.get('successful', 0)}  
          **Failed:** {results.get('failed', 0)}  
          **Mode:** {'üß™ DRY RUN' if results.get('dry_run') else '‚úÖ LIVE'}

          ## Platform Breakdown
          
          | Platform | Total | Successful | Failed | Success Rate |
          |----------|-------|------------|--------|--------------|
          """
          
          for platform, stats in sorted(stats_by_platform.items()):
              success_rate = (stats['successful'] / stats['total'] * 100) if stats['total'] > 0 else 0
              report += f"| {platform.title()} | {stats['total']} | {stats['successful']} | {stats['failed']} | {success_rate:.1f}% |\n"
          
          report += "\n## Campaign Details\n\n"
          
          for i, campaign in enumerate(results.get('campaigns', []), 1):
              report += f"### {i}. {campaign['name']}\n\n"
              report += f"- **Applications:** {campaign['applications']}\n"
              report += f"- **Successful:** {campaign['successful']}\n"
              report += f"- **Failed:** {campaign['failed']}\n\n"
              
              if campaign.get('platforms'):
                  report += "**Platform Results:**\n\n"
                  for platform in campaign['platforms']:
                      report += f"- {platform['platform']}: {platform['successful']}/{platform['applications']} successful\n"
                  report += "\n"
              
              if campaign.get('errors'):
                  report += "**Errors:**\n\n"
                  for error in campaign['errors']:
                      report += f"- ‚ö†Ô∏è {error}\n"
                  report += "\n"
          
          # Historical context
          report += f"""
          ## Historical Context

          - **Total Applications to Date:** {len(all_applications)}
          - **LinkedIn Network Targets:** {len(linkedin_targets)}
          - **Last Execution:** {results.get('end_time', 'N/A')}

          ## Next Steps

          1. **Monitor Applications:** Check platform dashboards for responses
          2. **Follow-up Actions:** Review pending applications that need follow-up
          3. **Network Engagement:** Continue LinkedIn networking activities
          4. **Research Companies:** Use Glassdoor data to prepare for interviews

          ## Platform-Specific Actions
          
          """
          
          if 'linkedin' in stats_by_platform:
              report += """### LinkedIn
          - Check pending connection requests
          - Review daily action plan
          - Engage with accepted connections
          - Monitor InMail responses

          """
          
          if 'indeed' in stats_by_platform:
              report += """### Indeed
          - Monitor application status in Indeed dashboard
          - Check for employer messages
          - Review saved jobs and alerts
          - Update job preferences if needed

          """
          
          if 'reed' in stats_by_platform:
              report += """### Reed
          - Check Reed inbox for responses
          - Review application history
          - Update CV on Reed profile
          - Set up job alerts

          """
          
          if 'glassdoor' in stats_by_platform:
              report += """### Glassdoor
          - Review company research queue
          - Complete interview prep guides
          - Monitor salary comparisons
          - Read recent company reviews

          """
          
          report += """
          ---
          *Report generated by Multi-Platform Job Application System*  
          *For issues or improvements, create a GitHub issue*
          """
          
          # Save report
          report_file = tracking_dir / 'reports' / f'campaign_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.md'
          report_file.parent.mkdir(parents=True, exist_ok=True)
          
          with open(report_file, 'w') as f:
              f.write(report)
          
          print(f"‚úÖ Report saved to: {report_file}")
          
          # Also save summary version
          summary_file = tracking_dir / 'reports' / 'latest_campaign_summary.md'
          with open(summary_file, 'w') as f:
              f.write(report)
          
          print(f"‚úÖ Summary saved to: {summary_file}")
          print("\n" + "=" * 70)
          print("üìä REPORT GENERATION COMPLETE")
          print("=" * 70)
          PYTHON_SCRIPT

      - name: Commit reports
        uses: ./.github/actions/safe-git-push
        with:
          commit-message: "üìä Campaign report generated - $(date +'%Y-%m-%d %H:%M')"
          files: "job_search/application_packages/ job_search/applications.json job_search/analytics.json job_search/reports/"
  cleanup-old-campaigns:
    name: Archive Completed Campaigns
    needs: execute-campaigns
    if: success()
    runs-on: ubuntu-latest
    timeout-minutes: 5
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Archive executed campaigns
        run: |
          python3 << 'PYTHON_SCRIPT'
          import json
          from pathlib import Path
          from datetime import datetime
          import shutil
          
          campaigns_dir = Path('scheduled-campaigns')
          archive_dir = Path('scheduled-campaigns/archive')
          archive_dir.mkdir(exist_ok=True)
          
          results_file = Path('campaign_execution_results.json')
          
          if not results_file.exists():
              print("No execution results found")
              exit(0)
          
          with open(results_file, 'r') as f:
              results = json.load(f)
          
          # Archive campaigns that ran with "immediate" or "now" mode
          archived_count = 0
          
          for campaign in results.get('campaigns', []):
              campaign_file = campaigns_dir / f"{campaign['name']}.json"
              
              if campaign_file.exists():
                  # Load to check send mode
                  with open(campaign_file, 'r') as f:
                      config = json.load(f)
                  
                  send_mode = config.get('send', '').lower()
                  
                  # Archive immediate/now campaigns after execution
                  if send_mode in ['immediate', 'now']:
                      timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                      archive_path = archive_dir / f"{campaign['name']}_{timestamp}.json"
                      
                      # Add execution metadata
                      config['_execution'] = {
                          'executed_at': results.get('end_time'),
                          'applications': campaign['applications'],
                          'successful': campaign['successful'],
                          'failed': campaign['failed']
                      }
                      
                      # Save to archive
                      with open(archive_path, 'w') as f:
                          json.dump(config, f, indent=2)
                      
                      # Remove original
                      campaign_file.unlink()
                      
                      archived_count += 1
                      print(f"‚úÖ Archived: {campaign['name']}")
          
          print(f"\nüì¶ Archived {archived_count} campaign(s)")
          PYTHON_SCRIPT

      - name: Commit archive changes
        uses: ./.github/actions/safe-git-push
        with:
          commit-message: "üì¶ Archived completed campaigns - $(date +'%Y-%m-%d')"
          files: "scheduled-campaigns/"
      
